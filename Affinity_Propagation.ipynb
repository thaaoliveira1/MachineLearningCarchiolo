{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affinity Propagation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affinity Propagation is a clustering algorithm used in natural language processing (NLP) for sentiment analysis. Clustering algorithms group similar objects together based on a certain similarity metric. In the case of sentiment analysis, the objects are textual documents or sentences, and the similarity metric is based on the sentiment expressed in the text.\n",
    "\n",
    "Affinity Propagation is particularly useful for sentiment analysis because it does not require the number of clusters to be predefined, which can be difficult to determine in advance. Instead, it automatically determines the number of clusters by finding the most representative data points, known as exemplars, for each cluster.\n",
    "\n",
    "The algorithm works by iteratively passing messages between data points until a set of exemplars is identified that best represent the entire data set. These exemplars can then be used to assign new data points to the appropriate cluster.\n",
    "\n",
    "Overall, Affinity Propagation is a powerful tool for sentiment analysis in NLP because it can automatically identify the most representative data points for each cluster without requiring a priori knowledge of the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bita\\AppData\\Local\\Temp\\ipykernel_12056\\3876859935.py:3: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  y_train = pd.read_csv('y_train.csv', squeeze=True, encoding=DATASET_ENCODING)[:-1]\n",
      "C:\\Users\\Bita\\AppData\\Local\\Temp\\ipykernel_12056\\3876859935.py:4: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  y_test = pd.read_csv('y_test.csv', squeeze=True, encoding=DATASET_ENCODING)[:-1]\n",
      "C:\\Users\\Bita\\AppData\\Local\\Temp\\ipykernel_12056\\3876859935.py:5: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  X_test = pd.read_csv('X_test.csv', squeeze=True, encoding=DATASET_ENCODING)[:-1]\n",
      "C:\\Users\\Bita\\AppData\\Local\\Temp\\ipykernel_12056\\3876859935.py:6: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  X_train = pd.read_csv('X_train.csv', squeeze=True, encoding=DATASET_ENCODING)[:-1]\n"
     ]
    }
   ],
   "source": [
    "#Load csv files\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "y_train = pd.read_csv('y_train.csv', squeeze=True, encoding=DATASET_ENCODING)[:-1]\n",
    "y_test = pd.read_csv('y_test.csv', squeeze=True, encoding=DATASET_ENCODING)[:-1]\n",
    "X_test = pd.read_csv('X_test.csv', squeeze=True, encoding=DATASET_ENCODING)[:-1]\n",
    "X_train = pd.read_csv('X_train.csv', squeeze=True, encoding=DATASET_ENCODING)[:-1]\n",
    "\n",
    "X_train.fillna('', inplace=True)\n",
    "X_test.fillna('', inplace=True)\n",
    "\n",
    "y_test = y_test.replace(4,1)\n",
    "y_train = y_train.replace(4,1)\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('x_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 6\n",
      "Cluster 0:\n",
      "[ids                                                  2321931262\n",
      "date                               Wed Jun 24 21:47:09 PDT 2009\n",
      "flag                                                   NO_QUERY\n",
      "user                                                     ahrris\n",
      "text          ['always', 'happen', 'maybe', 'rly', 'thinks',...\n",
      "word count                                                   10\n",
      "Name: 0, dtype: object]\n",
      "Cluster 1:\n",
      "[ids                              2065074756\n",
      "date           Sun Jun 07 07:50:15 PDT 2009\n",
      "flag                               NO_QUERY\n",
      "user                              shanajaca\n",
      "text          ['try', 'rach', 'xxxxxxxxxx']\n",
      "word count                                3\n",
      "Name: 1, dtype: object]\n",
      "Cluster 2:\n",
      "[ids                                                  1834918736\n",
      "date                               Mon May 18 04:36:46 PDT 2009\n",
      "flag                                                   NO_QUERY\n",
      "user                                            demoninmypocket\n",
      "text          ['mellicakes', 'im', 'scared', 'dumborelated',...\n",
      "word count                                                    8\n",
      "Name: 2, dtype: object]\n",
      "Cluster 3:\n",
      "[ids                                2227845921\n",
      "date             Thu Jun 18 13:42:21 PDT 2009\n",
      "flag                                 NO_QUERY\n",
      "user                                Katie1989\n",
      "text          ['missing', 'mitchell', 'webb']\n",
      "word count                                  3\n",
      "Name: 3, dtype: object]\n",
      "Cluster 4:\n",
      "[ids                                                  1979466427\n",
      "date                               Sun May 31 03:10:08 PDT 2009\n",
      "flag                                                   NO_QUERY\n",
      "user                                                 Sazzaroo90\n",
      "text          ['working', 'going', 'go', 'chill', 'lovely', ...\n",
      "word count                                                    6\n",
      "Name: 4, dtype: object]\n",
      "Cluster 5:\n",
      "[ids                                                  1997787108\n",
      "date                               Mon Jun 01 17:27:25 PDT 2009\n",
      "flag                                                   NO_QUERY\n",
      "user                                                    Janiqua\n",
      "text          ['finesseroyale', 'prob', 'damnwellll', 'lets'...\n",
      "word count                                                    9\n",
      "Name: 5, dtype: object]\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Perform clustering using Affinity Propagation\n",
    "af = AffinityPropagation().fit(X_vect)\n",
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = af.labels_\n",
    "\n",
    "# Print the number of clusters\n",
    "n_clusters = len(set(cluster_labels))\n",
    "print('Number of clusters: %d' % n_clusters)\n",
    "\n",
    "# Print the clusters and their associated text data\n",
    "clusters = {}\n",
    "for i, label in enumerate(cluster_labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []\n",
    "    clusters[label].append(X_train.iloc[i])\n",
    "for cluster in clusters:\n",
    "    print('Cluster %d:' % cluster)\n",
    "    print(clusters[cluster])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
